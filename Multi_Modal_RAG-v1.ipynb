{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cookbook for multi-modal (text + tables + images) RAG \n",
    "# (https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb)\n",
    "# (https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb) \n",
    "# + Option_3: Retrieve image summary but pass raw image to LLM for synthesis\n",
    "# pdf2image needs Poppler for Windows,\n",
    "# Go to: https://github.com/oschwartz10612/poppler-windows/releases\n",
    "# Download the latest Release-24.08.0.zip file.\n",
    "# make \"C:\\Program Files\\poppler\\\"poppler-24.08.0\"\n",
    "# Add Poppler to PATH: System Variables ---> New ---> \"C:\\Program Files\\poppler\\poppler-24.08.0\\Library\\bin\"\n",
    "# download and install \"Tesseract\" (https://github.com/UB-Mannheim/tesseract/wiki)\n",
    "# Add Tesseract to PATH: System Variables ---> New ---> \"C:\\Program Files\\Tesseract-OCR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2a1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/4-IntoCode/16_LangChain/AgilProjekt_multiModel/\"  # use / instead of \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246861d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path + \"AKAP1.pdf\",\n",
    "    # Using pdf format to find embedded image blocks\n",
    "    extract_images_in_pdf=True,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    "    chunking_strategy=\"by_title\",\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a28e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 197,\n",
       " \"<class 'unstructured.documents.elements.TableChunk'>\": 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139db9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "class Element(BaseModel):\n",
    "    type: str\n",
    "    text: Any\n",
    "\n",
    "\n",
    "# Categorize by type\n",
    "categorized_elements = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "\n",
    "# Tables\n",
    "table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
    "print(len(table_elements))\n",
    "\n",
    "# Text\n",
    "text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
    "print(len(text_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a30f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-vector retriever\n",
    "# Text and Table summaries\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc122f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "\n",
    "# Summary chain\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \") # use Google Gemini instead of OpenAI\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)    # gemini-1.5-flash instead of gemini-2.0-flash\n",
    "\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to text\n",
    "texts = [i.text for i in text_elements]\n",
    "\n",
    "# to avoid 429 error, we can use batch processing\n",
    "import time\n",
    "\n",
    "summaries = []\n",
    "for text in texts:\n",
    "    try:\n",
    "        result = summarize_chain.invoke(text)\n",
    "        summaries.append(result)\n",
    "        time.sleep(5)  # deal with 1 request per 5 seconds\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        time.sleep(30)  # if error, wait 30 seconds before retrying\n",
    "for text in texts:\n",
    "    result = summarize_chain.invoke(text)\n",
    "    print(result) # deal it one by one\n",
    "\n",
    "text_summaries = summarize_chain.batch(texts[:10], {\"max_concurrency\": 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text summary Result: (after running 19 minutes, and stopped by ResourceExhausted error)\n",
    "'''This is the header information for a research article published in the *Journal of Molecular and Cellular Cardiology*.  The article, titled \"A-kinase anchoring protein 1 (AKAP1) and its role in some cardiovascular diseases,\" was authored by Wenwen Marin from Qingdao University and focuses on AKAP1's involvement in cardiovascular illnesses.\n",
    "This abstract likely discusses the role of A-kinase anchoring proteins (AKAPs) in mitochondrial signaling pathways, specifically within the context of cardiovascular diseases.\n",
    "This review focuses on AKAP1, a mitochondrial A-kinase anchoring protein crucial for cardiac function.  It will summarize AKAP1's sequence, structure-function relationships with binding partners, and its role in the molecular mechanisms of cardiac hypertrophy.\n",
    "AKAP1 is a potential therapeutic target for cardiovascular disease, due to its involvement in hypoxia-induced myocardial infarction and endothelial dysfunction.\n",
    "AKAPs are essential \"conductors\" in cellular signal transduction, similar to a conductor leading an orchestra.  They position signaling molecules (enzymes, receptors, mRNA) in specific locations within the cell, optimizing signaling and maintaining homeostasis.\n",
    "AKAPs are scaffold proteins that bind to PKA regulatory subunits via an amphipathic alpha-helix, and also possess domains for anchoring signaling complexes to specific subcellular locations.\n",
    "A-kinase anchoring proteins (AKAPs) are crucial for precise regulation of cAMP signal transduction.  They localize key enzymes (e.g., adenylyl cyclase, phosphodiesterase, protein phosphatase) and factors (e.g., GPCRs) within cellular structures (plasma membrane, cytoskeleton, etc.) to facilitate efficient cAMP signaling.\n",
    "\n",
    "AKAPs enhance cAMP signaling efficiency by forming multi-functional complexes with various proteins (ion channels, kinases, GTPases, etc.), thus integrating signaling crosstalk.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b9b1c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table shows the expression levels of various AKAP (A-kinase anchoring proteins) family members (e.g., AKAP1, AKAP2, AKAP110) in a tissue or cell type, as assessed by antibody detection and RNA sequencing (HPA-RNA-seq).  Many showed low or undetectable expression levels.  Specific expression levels are given as numerical values (e.g., 0.0, 42, 75), but the units are not specified.\n",
      "The table shows gene expression data from two sources, GTEx RNA-seq and FANTOM5 CAGE.  The data includes numerical values (likely counts or percentages) but lacks clear column headers making precise interpretation impossible.  The numbers vary significantly between the two datasets.\n",
      "The table lists several protein motifs and their approximate amino acid residue ranges within a protein sequence.  Motifs include tubulin binding, leucine zipper, mitochondrial targeting sequence, PP1 binding domain, PKA/RII binding site, and Tudor domain.  Specific residue ranges are provided for some, while others are indicated more generally.\n"
     ]
    }
   ],
   "source": [
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "\n",
    "# to avoid 429 error, we can use batch processing\n",
    "import time\n",
    "\n",
    "summaries = []\n",
    "for table in tables:\n",
    "    try:\n",
    "        result = summarize_chain.invoke(table)\n",
    "        summaries.append(result)\n",
    "        time.sleep(5)  # deal with 1 request per 5 seconds\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        time.sleep(30)  # if error, wait 30 seconds before retrying\n",
    "for table in tables:\n",
    "    result = summarize_chain.invoke(table)\n",
    "    print(result) # deal it one by one\n",
    "\n",
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table summary Result:\n",
    "'''The table shows the expression levels of various AKAP (A-kinase anchoring proteins) family members (e.g., AKAP1, AKAP2, AKAP110) in a tissue or cell type, as assessed by antibody detection and RNA sequencing (HPA-RNA-seq).  Many showed low or undetectable expression levels.  Specific expression levels are given as numerical values (e.g., 0.0, 42, 75), but the units are not specified.\n",
    "The table shows gene expression data from two sources, GTEx RNA-seq and FANTOM5 CAGE.  The data includes numerical values (likely counts or percentages) but lacks clear column headers making precise interpretation impossible.  The numbers vary significantly between the two datasets.\n",
    "The table lists several protein motifs and their approximate amino acid residue ranges within a protein sequence.  Motifs include tubulin binding, leucine zipper, mitochondrial targeting sequence, PP1 binding domain, PKA/RII binding site, and Tudor domain.  Specific residue ranges are provided for some, while others are indicated more generally.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce37e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vectorstore\n",
    "# Use Multi Vector Retriever with summaries:\n",
    "# InMemoryStore stores the raw text, tables\n",
    "# vectorstore stores the embedded summaries\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00905c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RAG pipeline.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt template\n",
    "template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the role of AKAPs in the cardiovascular system?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
