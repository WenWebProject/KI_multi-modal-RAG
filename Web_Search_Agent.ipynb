{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install openai requests beautifulsoup4\n",
        "!pip install langgraph langchain openai gradio beautifulsoup4\n",
        "!pip install tavily-python\n",
        "!from tavily import TavilyClient\n",
        "!pip install langchain tavily-python openai\n",
        "!pip install python-dotenv\n",
        "from tavily import TavilyClient\n",
        "!pip install langchain_community\n",
        "!pip install --upgrade langchain langchain_community\n",
        "\n",
        "from langchain.llms import HuggingFaceHub\n",
        "!pip install --upgrade huggingface_hub\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import requests\n",
        "import gradio as gr\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API NewsAPI\n",
        "NEWS_API_URL = \"https://newsapi.org/v2/everything\"\n",
        "\n",
        "class Config:\n",
        "    @staticmethod\n",
        "    def setup():\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞\n",
        "        load_dotenv()\n",
        "        token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è LangChain, Tavily –∏ OpenAI\n",
        "        os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\", \"\")\n",
        "        os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\", \"\")\n",
        "        os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\", \"\")\n",
        "        os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
        "        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "        os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\", \"\")\n",
        "\n",
        "        if os.getenv(\"LANGSMITH_TRACING\", \"false\").lower() == \"true\":\n",
        "            os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞\n",
        "\n",
        "client = InferenceClient(token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n",
        "\n",
        "# –í—ã–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å\n",
        "response = client.text_generation(\n",
        "    \"Hi! Tell me something interesting..\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    temperature=0.7,\n",
        "    max_new_tokens=100,\n",
        ")\n",
        "\n",
        "print(response)\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-base\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
        "\n",
        "print(llm(\"Hi! Tell me something interesting..\"))\n",
        "\n",
        "# üß† –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç Tavily\n",
        "def tavily_search_tool(query: str) -> str:\n",
        "    tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "    results = tavily.search(query=query, search_depth=\"basic\")\n",
        "\n",
        "    summaries = []\n",
        "    for res in results['results'][:3]:\n",
        "        try:\n",
        "            html = requests.get(res['url']).content\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "            summaries.append(text[:500])\n",
        "        except Exception as e:\n",
        "            summaries.append(f\"[Fehler {res['url']}: {e}]\")\n",
        "    return '\\n\\n'.join(summaries)\n",
        "\n",
        "\n",
        "# ‚úÖ –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç LangChain\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Tavily Web Search\",\n",
        "        func=tavily_search_tool,\n",
        "        description=\"\"Searches for up-to-date market information on the Internet at the user's request\"\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# üéØ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–∞\n",
        "def agent_handler(user_input):\n",
        "    try:\n",
        "        response = agent.run(user_input)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Agent Error: {str(e)}\"\n",
        "\n",
        "# üéõ –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio\n",
        "gr.Interface(\n",
        "    fn=agent_handler,\n",
        "    inputs=gr.Textbox(label=\"Your query (eg: What news is impacting Google today?))\"),\n",
        "    outputs=gr.Textbox(label=\"Agent's response\"),\n",
        "    title=\"üß† Web search agent based onTavily + OpenAI\",\n",
        "    description=\"This agent searches for fresh news and information using Tavily and analyzes it using GPT.\"\n",
        ").launch()\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "Web_Search_Agent = create_react_agent(llm, [retrieve])\n"
      ],
      "metadata": {
        "id": "HQ2TUSEYnwjR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}