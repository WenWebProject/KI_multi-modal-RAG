{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6-2mduVjd1r"
      },
      "outputs": [],
      "source": [
        "# Agent analitic plotlib5\n",
        "\n",
        "#!pip install huggingface_hub\n",
        "#!pip install langchain huggingface_hub transformers\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "#!pip install huggingface_hub[hf_xet]\n",
        "!pip install hf_xet\n",
        "#!pip install --upgrade transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "!pip install torch\n",
        "!pip install plotly\n",
        "\n",
        "\n",
        "!pip install --upgrade transformers langchain huggingface_hub torch\n",
        "\n",
        "\n",
        "#hf_pipeline = pipeline(\"text-generation\", model=\"distilgpt2\", max_new_tokens=100)\n",
        "\n",
        "!pip install huggingface_hub[hf_xet]\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool\n",
        "#from langchain.llms import HuggingFace\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from prophet import Prophet\n",
        "import plotly.graph_objects as go\n",
        "from typing import List, Tuple\n",
        "import time\n",
        "import logging\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from transformers import pipeline\n",
        "\n",
        "# Schlüssel werden geladen von .env\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "# Setting up the logger\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# class CSVForecastTool(BaseTool):CSV с Prophet\n",
        "class CSVForecastTool(BaseTool):\n",
        "    name: str = \"CSVForecast\"\n",
        "    description: str = \"Predicts time series from CSV files (columns Date и Close)\"\n",
        "    #Add an analysis tool CSV\n",
        "\n",
        "    def _run(self, company_name: str) -> List[Tuple[str, go.Figure]]:\n",
        "     #   company_folder = f\"parsed/{company_name.lower()}/\"\n",
        "        company_folder = f\"parsed/{company_name}/\"\n",
        "\n",
        "        if not os.path.exists(company_folder):\n",
        "            return [(f\"Error: Folder for company{company_name} not found.\", None)]\n",
        "\n",
        "        csv_files = glob.glob(os.path.join(company_folder, \"*.csv\"))\n",
        "        if not csv_files:\n",
        "            return [(f\"Error: No CSV files for company{company_name}.\", None)]\n",
        "\n",
        "        results = []\n",
        "        for file in csv_files:\n",
        "            try:\n",
        "                df = pd.read_csv(file)\n",
        "                if \"Date\" not in df.columns or \"Close\" not in df.columns:\n",
        "                    continue\n",
        "\n",
        "                # Data transformation for Prophet\n",
        "                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "                df = df.dropna(subset=[\"Date\", \"Close\"])\n",
        "                df = df.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
        "\n",
        "                # Forecasting with Prophett\n",
        "                model = Prophet()\n",
        "                model.fit(df)\n",
        "                future = model.make_future_dataframe(periods=90)\n",
        "                forecast = model.predict(future)\n",
        "\n",
        "                # Zeichnen eines Diagramms\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], mode='lines', name='Forecast'))\n",
        "                fig.add_trace(go.Scatter(x=df['ds'], y=df['y'], mode='markers', name='Historical data'))\n",
        "                fig.update_layout(title=f\"Forecast fur {company_name}\", xaxis_title=Datum\", yaxis_title=\"Closing price\")\n",
        "\n",
        "                # Text generation\n",
        "                change = forecast['yhat'].iloc[-1] - forecast['yhat'].iloc[-91]\n",
        "                change_pct = (change / forecast['yhat'].iloc[-91]) * 100\n",
        "                trend = \"Height\" if change > 0 else \"Fall\"\n",
        "                result_text = f\"{company_name}: Прогноз на следующий квартал: {trend} ~{abs(change_pct):.2f}%\"\n",
        "                results.append((result_text, fig))\n",
        "\n",
        "            except Exception as e:\n",
        "                results.append((f\"error while processing {file}: {str(e)}\", None))\n",
        "\n",
        "        return results\n",
        "\n",
        "# Rechner-Tool\n",
        "class CalculatorTool(BaseTool):\n",
        "    name: str = \"Calculator\"\n",
        "    description: str = \"Führt mathematische Berechnungen durch\"\n",
        "\n",
        "    def _run(self, query: str) -> str:\n",
        "        try:\n",
        "            return str(eval(query))\n",
        "        except Exception as e:\n",
        "            return f\"Rechenfehler: {str(e)}\"\n",
        "\n",
        "# Создание инструментов\n",
        "csv_forecast_tool = CSVForecastTool()\n",
        "calculator_tool = CalculatorTool()\n",
        "\n",
        "tools = [\n",
        "    Tool(name=\"CSVForecast\", func=csv_forecast_tool._run, description=\"Прогноз по CSV для компании\"),\n",
        "    Tool(name=\"Calculator\", func=calculator_tool._run, description=\"Математический калькулятор\"),\n",
        "   # Tool(name=csv_forecast_tool.name, func=csv_forecast_tool._run, description=csv_forecast_tool.description)\n",
        "]\n",
        "\n",
        "# Инициализация LLM с Hugging Face\n",
        "# Загружаем модель и токенизатор\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "hf_pipeline = pipeline(\"text-generation\", model=\"gpt2\", max_new_tokens=100)\n",
        "\n",
        "# Генерация текста\n",
        "output = hf_pipeline(\"Hello, how are you?\")\n",
        "print(output[0]['generated_text'])\n",
        "\n",
        "output = hf_pipeline(\"Hello, how are you?\")\n",
        "print(output)\n",
        "#llm_hf = pipeline(\"text-generation\", model=\"gpt2\")                     #HuggingFace(pipeline=hf_pipeline)\n",
        "\n",
        "# Обёртка в LangChain совместимый llm\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "# Инициализация агента\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,                            #llm_hf,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Пример вызова агента\n",
        "query = \"Проанализируй Nvidia и построй график\"\n",
        "response = agent.run(query)\n",
        "\n",
        "query = \"Проанализируй Nvidia за 6 месяцев, покажи график и спрогнозируй на следующий квартал.\"\n",
        "response = agent.run(query)\n",
        "\n",
        "# Проверка и отображение\n",
        "if isinstance(response, list) and isinstance(response[0], tuple):\n",
        "    text, fig = response[0]\n",
        "    print(text)\n",
        "    if fig:\n",
        "        fig.show()\n",
        "else:\n",
        "    print(\"Ответ агента:\", response)\n",
        "\n",
        "#if isinstance(response, list):\n",
        "#    for result in response:\n",
        " #       if isinstance(result, tuple):\n",
        "  #          text, figure = result\n",
        "  #          print(text)\n",
        "   #         if figure:\n",
        "    #            figure.show()  # Отображение графика\n",
        "    #    else:\n",
        "    #        print(result)  # Если это просто ошибка или информация\n",
        "#else:\n",
        " #   print(\"Ответ от агента не является списком. Полученный ответ:\", response)\n",
        "\n",
        "# Пример запроса\n",
        "query = \"Сколько будет 2 + 2?\"\n",
        "response = agent.run(query)\n",
        "print(response)\n",
        "\n",
        "# Вывод результата\n",
        "if isinstance(response, list):\n",
        "    for result in response:\n",
        "        if isinstance(result, tuple):\n",
        "            text, figure = result\n",
        "            print(text)\n",
        "            if figure:\n",
        "                figure.show()  # Отображение графика\n",
        "        else:\n",
        "            print(result)  # Если это просто ошибка или информация\n",
        "else:\n",
        "    print(\"Ответ от агента не является списком. Полученный ответ:\", response)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "Data_Science_Agent = create_react_agent(llm, [retrieve])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
